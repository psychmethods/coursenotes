[["index.html", "Psychology Research Methods For Psych Minors Welcome to PSY 310", " Psychology Research Methods For Psych Minors S. Mason Garrison 2022-02-20 Welcome to PSY 310 Welcome to class! This website is designed to accompany Mason Garrisons Psych Methods for Psych Minors (PMPM). This class is a undergraduate-level psychology course at Wake Forest University. I encourage anyone who is methods-curious to work their way through these course notes. The course notes include lectures, worked examples, readings, activities, and labs. You can find the current version of the course syllabus here, along with all of the other syllabi for my classes. All the embedded lecture videos can be found on a youtube playlist. "],["attribution.html", "Attribution Major Attributions Additional Attributions", " Attribution This class leans heavily on other peoples materials and ideas. I have done my best to document the origin of the materials and ideas. In particular, I have noted those people whose work has been a major contribution as well as those who have additional contributions. You can see specific changes by examining the [edit history on the git repo][edits] Major Attributions Jenny Bryans (jennybryan) STAT 545 Joe Rodgerss 2101 Alisa Beyer Introduction to Statistics for Psychology Danielle Navarros Learning Statistics with R Additional Attributions Eric Stones 210 Eranda Jayawickremes 310 "],["license.html", "License", " License This work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License. This information is a human-readable summary of (and not a substitute for) the license. Please see https://creativecommons.org/licenses/by-sa/4.0/legalcode for the full legal text. You are free to: Sharecopy and redistribute the material in any medium or format Remixremix, transform, and build upon the material for any purpose, even commercially. The licensor cannot revoke these freedoms as long as you follow the license terms. Under the following terms: AttributionYou must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use. ShareAlikeIf you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original. No additional restrictionsYou may not apply legal terms or technological measures that legally restrict others from doing anything the license permits. Notices: You do not have to comply with the license for elements of the material in the public domain or where your use is permitted by an applicable exception or limitation. No warranties are given. The license may not give you all of the permissions necessary for your intended use. For example, other rights such as publicity, privacy, or moral rights may limit how you use the material. "],["colophon.html", "Colophon", " Colophon These notes was written in bookdown inside RStudio. The [website][web] is hosted with github, The complete source is available from [github][git]. The book style is based on a design by Desirée De Leon. This version of the notes was built with: #&gt; Finding R package dependencies ... Done! #&gt; setting value #&gt; version R version 4.1.2 (2021-11-01) #&gt; os Windows 10 x64 (build 19044) #&gt; system x86_64, mingw32 #&gt; ui RTerm #&gt; language (EN) #&gt; collate English_United States.1252 #&gt; ctype English_United States.1252 #&gt; tz America/New_York #&gt; date 2022-02-20 #&gt; pandoc 2.11.4 @ C:/Program Files/RStudio/bin/pandoc/ (via rmarkdown) Along with these packages: "],["dont-miss-module-00.html", "Dont Miss Module 00 0.1 Learning Goals for this Module (Chapter 0) 0.2 To-Do List 0.3 Course Modality 0.4 Knowledge is Power 0.5 Meet Mason 0.6 Website Tour", " Dont Miss Module 00 This overview is designed to orient you to the class as well as show you the rationale underlying them. Every module will follow a similar structure. First, Ill provide an overview of the topic and provide actionable learning goals. Please watch the videos from this playlist and work your way through the notes. Although the module-level playlists are embedded in the course, you can find the full-course video playlist here. By the end of each module, you should be able to achieve all the learning goals outlined below. For this module those goals are 0.1 Learning Goals for this Module (Chapter 0) Explain the structure of the course. Understand the rationale underlying the structure of the course. Explain the expectations for your section. 0.2 To-Do List I provide a list of tasks youll need to do to complete the module. I provide this list to give the class structure. These tasks are broken down into three stages: explore, engage, and evaluate These stages are designed to be sequential. Complete the explore tasks first. Second, complete the engage tasks. Last, complete the evaluation. For each stage, I will explicitly indicate whether specific tasks are required or merely, recommended. The exploring portion of the class introduces you to the content of the module. It will consist of reading texts and viewing videos. Relative to the other two portions of the module, its more passive. The engagement portion of the class facilitates you engaging with the material, interacting with the other members of the learning community. Students will complete two engagement activities. Most of the time, Ill provide multiple choices for the engagement portion of the module. In order to successfully complete Module 0, please do the following: Explore: Skim: the preface of your textbook (Optional) View: the embedded videos connected to the learning goals. Engage: Create: a brief video introducing yourself and post it on the discussion board. Complete: the following survey. Evaluate: 0.3 Course Modality This class is a flipped class. The online portions are asynchronous, and often contain pre-recorded videos. Ive created a video highlighting how to be a successful asynchronous learner. Much of this information comes from Northeastern Universitys Tips for Taking Online Classes 0.3.1 Productivity During Lockdown 0.4 Knowledge is Power This brief video is covers the icebreaker I do in all of my classes. I encourage you to watch it. In it, I discuss stereotype threats and statistics anxiety. 0.5 Meet Mason Mason Garrison is an assistant professor of quantitative psychology at Wake Forest University. She earned her PhD and MS in Quantitative Methods from Vanderbilt University, and her AB in Economics &amp; Psychology from Washington University in St. Louis. Her research is an eclectic mix of behavior genetics, individual differences (e.g., personality, intelligence), and statistics. On a more humanizing note, at the start of quarantine, Mason was fostering two feral kittens. They had been living behind the freshman dorms. She made the mistake of naming them. So now she has three cats Tukey (namesake: John Tukey) Archie (namesake: Archimedes) Annie (namesake: Anne Anastasi) 0.6 Website Tour "],["guidance.html", "Guidance 0.7 Syllabus 0.8 Materials", " Guidance 0.7 Syllabus This document is not the syllabus. Please refer to Mason Garrisons syllabus here: https://smasongarrison.github.io/syllabi/ 0.8 Materials 0.8.1 Hardware This class requires that you have a laptop that can run R. 0.8.2 Required Texts The text is intended to supplement the videos, lecture notes, tutorials, activities, and labs. You probably need to consume all of them in order to be successful in this class. 0.8.3 Software 0.8.3.1 R and RStudio R is a free software environment for statistical computing and graphics. It compiles and runs on a wide variety of UNIX platforms, Windows, and MacOS. RStudio is a free integrated development environment (IDE), a powerful user interface for R. 0.8.3.2 Git and Github Git is a version control system. Its original purpose was to help groups of developers work collaboratively on big software projects. Git manages the evolution of a set of files  called a repository  in a structured way. Think of it like the Track Changes features from Microsoft Word. Github is a free IDE and hosting service for Git. As a Wake Forest student, you should be able to access the GitHub Student Developer Pack for free. It includes a free PRO upgrade for your github account. "],["welcome-to-probability.html", "1 Welcome to Probability 1.1 What is probability? 1.2 Probability &amp; Frequency Distributions 1.3 Probability in Normal Distributions 1.4 Considerations in understanding probability and inferential statistics: sampling 1.5 More Probability Terms", " 1 Welcome to Probability In this lesson, we start to move away from descriptive statistics and begin our transition into inferential statistics. Recall that the goal of inferential statistics is to draw conclusions or make predictions about large populations by using data from smaller samples that represent that population. Probability is the underlying concept of inferential statistics and forms a direct link between samples and the population that they come from. In this chapter we will focus only on the principles and ideas necessary to lay the groundwork for future inferential statistics. We accomplish this by quickly tying the concepts of probability to what we already know about normal distributions and z-scores. 1.1 What is probability? Informally, we usually think of probability as a number that describes the likelihood of some event occurring, which ranges from zero (impossibility) to one (certainty). Probability can be discussed more vaguely. Chances are low it will rain today. Given there are no clouds, chances are low it will rain today. Given is the word we use to state what the conditions are. As the conditions change, so does the probability. Thus, if it were cloudy and windy outside, we might say, given the current weather conditions, there is a high probability that it is going to rain. It should also be noted that the terms low and high are relative and vague, and they will likely be interpreted different by different people (in other words: given how vague the terminology was, the probability of different interpretations is high). In statistics, most of the time we try to use more precise language or, even better, numbers to represent the probability of our event. Regardless, the basic structure and logic of our statements are consistent with how we speak about probability using numbers and formulas. Sometimes probabilities will instead be expressed in percentages, which range from zero to one hundred, as when the weather forecast predicts a twenty percent chance of rain today. In each case, these numbers are expressing how likely that particular event is, ranging from absolutely impossible (0%) to absolutely certain (100%). When we speak of the probability of something happening, we are talking how likely it is that thing will happen based on the conditions present. To formalize probability theory, we first need to define a few terms: Probability theory is the branch of mathematics that deals with chance and uncertainty. It forms an important part of the foundation for statistics, because it provides us with the mathematical tools to describe uncertain events. The study of probability arose in part due to interest in understanding games of chance, like cards or dice. These games provide useful examples of many statistical concepts, because when we repeat these games the likelihood of different outcomes remains (mostly) the same. To calculate probability, we need an activity that produces or observes an outcome is needed. This is typically an experiment or any situation or activity in which the result is not known in advance. Examples are the outcome for: the weather outside, flipping a coin, rolling a 6-sided die, or trying a new route to work to see if its faster than the old route. We also need to know the known outcomes of the activity/event/experiment. The sample space is the set of possible outcomes for an activity. We represent these by listing them within a set of squiggly brackets. For rain is {rain, not rain} For a coin flip, the sample space is {heads, tails}. For a six-sided die, the sample space is each of the possible numbers that can appear: {1,2,3,4,5,6}. For the amount of time it takes to get to work, the sample space is all possible real numbers greater than zero (since it cant take a negative amount of time to get somewhere, at least not yet). We wont bother trying to write out all of those numbers within the brackets. An outcome or event is a subset of the sample space to examine specific probability. In principle, it could be one or more of possible outcomes in the sample space, but here we will focus primarily on elementary events which consist of exactly one possible outcome. An event is a catch-all term to talk about any specific thing happening. For example, this could be it rains, obtaining heads in a single coin flip, rolling a 4 on a throw of the die, or taking 21 minutes to get home by the new route. In statistics, we usually define probability as the expected relative frequency of a particular outcome. The relative frequency is the number of times an event takes place relative to the number of times it could have taken place. Lets look at a slightly deeper example before we learn a basic probability formula. Say we have a regular, six-sided die (note that die is singular and dice is plural, a distinction that can be hard to get correct on the first try) and want to know how likely it is that we will roll a 1. That is, what is the probability of rolling a 1, given that the die is not weighted (which would introduce what we call a bias, though that is beyond the scope of this chapter). We could roll the die and see if it is a 1 or not, but that wont tell us about the probability, it will only tell us a single result. We could also roll the die hundreds or thousands of times, recording each outcome and seeing what the final list looks like, but this is time-consuming, and rolling a die that many times may lead down a dark path to gambling or, worse, playing Dungeons &amp; Dragons. What we need is a simple equation that represents what we are looking for and what is possible. To calculate the probability of an event, which here is defined as rolling a 1 on an unbiased die, we need to know two things: how many outcomes satisfy the criteria of our event (stated different, how many outcomes would count as what we are looking for) and the total number of outcomes possible. In our example, only a single outcome, rolling a 1, will satisfy our criteria, and there are a total of six possible outcomes (rolling a 1, rolling a 2, rolling a 3, rolling a 4, rolling a 5, and rolling a 6). Thus, the probability of rolling a 1 on an unbiased die is 1 in 6 or 1/6. Put into an equation using generic terms, we get: Probability = \\(\\frac{Number of Favorable (desired) outcomes}{Total number of possible Outcomes}\\) We can also using P( ) as shorthand for probability and we can use A as shorthand for an event: P(A) = \\(\\frac{Number of Favorable outcomes to A}{Total number of possible Outcomes}\\) Probability is usually symbolized by the letter p. The actual probability number is usually written as a decimal, though sometimes fractions or percentages are used. An event with a 50-50 chance is usually written as p = .5 but it could be written as p = 1/2 or p = 50%. It is also common to see probability written as being less than some value, using the less than (&lt;) sign. For example, p &lt; .05 means the probability of the event taking place is less than .05 or less than 5%. Using the above equation, lets calculate the probability of rolling an even number on this die: P(even number) = 2, 4, or 6/1, 2, 3, 4, 5, or 6 = 3/6 = .5. So we have a 50% chance of rolling an even number of this die. Lets look at another example, lets say that we are interested in knowing the probability of rain in Phoenix. We first have to define the activity  lets say that we will look at the National Weather Service data for each day in 2020 and determine whether there was any rain at the downtown Phoenix weather station. According to these data, in 2020 there were 15 rainy days. To compute the probability of rain in Phoenix, we simply divide the number of rainy days by the number of days counted (365), giving p(rain in PHX in 2020) = 0.04. Now that we have a probability formula, we can outline the formal features of probability (first defined by the Russian mathematician Andrei Kolmogorov). These are the features that a value has to have if it is going to be a probability. Probability cannot be negative. The total probability of all outcomes in the sample space is 1; that is, if we take the probability of each event and add them up, they must sum to 1. This is interpreted as saying Take all of the possible events and add up their probabilities. These must sum to one. The probability of any individual event cannot be greater than one. - This is implied by the previous point; since they must sum to one, and they cant be negative, then any particular probability cannot exceed one. To summarize, the probability that an event happens is the number of outcomes that qualify as that event (i.e. the number of ways the event could happen) compared to the total number of outcomes (i.e. how many things are possible). The principles laid out here operate under a certain set of conditions and can be elaborated into ideas that are complex yet powerful and elegant. However, such extensions are not necessary for a basic understanding of statistics, so we will end our discussion on the math of probability here. We will now return to a more familiar topic. This idea then brings us back around to our normal distribution, which can also be broken up into regions or areas, each of which are bounded by one or two z-scores and correspond to all z- scores in that region. The probability of randomly getting one of those z-scores in the specified region can then be found on a Standard Normal Distribution Table. Thus, the larger the region, the more likely an event is, and vice versa. Because the tails of the distribution are, by definition, smaller and we go farther out into the tail, the likelihood or probability of finding a result out in the extremes becomes small. 1.2 Probability &amp; Frequency Distributions For our purposes, we will see shortly that the normal distribution is the key to how probability works. If you toss a fair coin four times, the outcomes may not be two heads and two tails. However, if you toss the same coin 4,000 times, the outcomes will be close to half heads and half tails. The expected theoretical probability of heads in any one toss is 1/2 or 0.5. Even though the outcomes of a few repetitions are uncertain, there is a regular pattern of outcomes when there are many repetitions (law of large numbers). The pattern tends to resemble a symmetrical normal distribution. To help us think about probability, population, and inferential statistics we are going to use a frequency distribution because it can be seen as representing an entire population. This can be seen as a parallel concept because if all scores are represented in a frequency distribution it can function as a normal distribution. Using the empirical rule we know that different portions of the histogram can represent different proportions of the population and the terms proportions and probabilities mean the same thing. This means that a proportion of the histogram can correspond to the probability of a population. 1.3 Probability in Normal Distributions Recall that the normal distribution has an area under its curve that is equal to 1 and that it can be split into sections by drawing a line through it that corresponds to a given z-score. Because of this, we can interpret areas under the normal curve as probabilities that correspond to z-scores. In this section, we are going to link together the concepts of population, probability, and z-scores. We learned earlier that a frequency distribution can represent an entire population of scores. The shape of a frequency distribution for an entire population forms a symmetrical normal curve and certain proportions can be assigned to specific parts of the distribution. Figure 1.1: Z-Score Distribution The graph above only shows us some of the proportions associated with specific z-score values but the Unit Normal Table lists all possible values for a normal distribution. This means that we can use z-scores to help us find the specific probability for a specific outcome or event. First, lets look back at the area between z = -1.00 and z = 1.00 presented in the next figure. Figure 1.2: 68% data come from the blue-shaded region We were told earlier that this region contains 68% of the area under the curve. Thus, if we randomly chose a z-score from all possible z-scores, there is a 68% chance that it will be between z = -1.00 and z = 1.00 because those are the z-scores that satisfy our criteria. Just like a pie chart is broken up into slices by drawing lines through it, we can also draw a line through the normal distribution to split it into sections. Take a look at the normal distribution in Figure 3 which has a line drawn through it as z = 1.25. This line creates two sections of the distribution: the smaller section called the tail and the larger section called the body. Differentiating between the body and the tail does not depend on which side of the distribution the line is drawn. All that matters is the relative size of the pieces: bigger is always body. Figure 1.3: Body and tail of the normal distribution As you can see, we can break up the normal distribution into 3 pieces (lower tail, body, and upper tail) as in Figure 2 or into 2 pieces (body and tail) as in Figure 3. We can then find the proportion of the area in the body and tail based on where the line was drawn (i.e. at what z-score). Mathematically this is done using calculus. Fortunately, the exact values are given you to you in a Standard Normal Distribution Table, also known at the z-table. Using the values in this table, we can find the area under the normal curve in any body, tail, or combination of tails no matter which z-scores are used to define them. The z-table presents the values for the area under the curve to the left of the positive z-scores from 0.00-3.00 (technically 3.09), as indicated by the shaded region of the distribution at the top of the table. To find the appropriate value, we first find the row corresponding to our z-score then follow it over until we get to the column that corresponds to the number in the hundredths place of our z-score. For example, suppose we want to find the area in the body for a z-score of 1.62. We would first find the row for 1.60 then follow it across to the column labeled (1.60 + 0.02 = 1.62) and find 0.9474 (see Figure 4). Thus, the odds of randomly selecting someone with a z-score less than (to the left of) z = 1.62 is 94.74% because that is the proportion of the area taken up by values that satisfy our criteria. Figure 1.4: Using the z-table to find the area in the body to the left of z = 1.62 The z-table only presents the area in the body for positive z-scores because the normal distribution is symmetrical. Thus, the area in the body of z = 1.62 is equal to the area in the body for z = -1.62, though now the body will be the shaded area to the right of z (because the body is always larger). When in doubt, drawing out your distribution and shading the area you need to find will always help. The table also only presents the area in the body because the total area under the normal curve is always equal to 1.00, so if we need to find the area in the tail for z = 1.62, we simply find the area in the body and subtract it from 1.00 (1.00  0.9474 = 0.0526). Lets look at another example. This time, lets find the area corresponding to z- scores more extreme than z = -1.96 and z = 1.96. That is, lets find the area in the tails of the distribution for values less than z = -1.96 (farther negative and therefore more extreme) and greater than z = 1.96 (farther positive and therefore more extreme). This region is illustrated in Figure 5. Figure 1.5: Area in the tails beyond z = -1.96 and z = 1.96 Lets start with the tail for z = 1.96. If we go to the z-table we will find that the body to the left of z = 1.96 is equal to 0.9750. To find the area in the tail, we subtract that from 1.00 to get 0.0250. Because the normal distribution is symmetrical, the area in the tail for z = -1.96 is the exact same value, 0.0250. Finally, to get the total area in the shaded region, we simply add the areas together to get 0.0500. Thus, there is a 5% chance of randomly getting a value more extreme than z = -1.96 or z = 1.96 (this particular value and region will become incredibly important later on). Finally, we can find the area between two z-scores by shading and subtracting. Figure 6 shows the area between z = 0.50 and z = 1.50. Because this is a subsection of a body (rather than just a body or a tail), we must first find the larger of the two bodies, in this case the body for z = 1.50, and subtract the smaller of the two bodies, or the body for z = 0.50. Aligning the distributions vertically, as in Figure 6, makes this clearer. From the z-table, the area in the body for z = 1.50 is 0.9332 and the area in the body for z = 0.50 is 0.6915. Subtracting these gives us 0.9332  0.6915 = 0.2417. Figure 1.6: Area between z = 0.50 and 1.50, along with the corresponding areas in the body 1.4 Considerations in understanding probability and inferential statistics: sampling Recall that the goal of inferential statistics is to draw conclusions or make predictions about large populations by using data from smaller samples that represent that population. Probability is the underlying concept of inferential statistics and forms a direct link between samples and the population that they come from. (#fig:inf_probability)The relationship between inferential statistics and probability As we learned earlier, gathering information about an entire population often costs too much or is virtually impossible. Instead, we use a sample of the population. A sample should have the same characteristics as the population it is representing. Random sampling is one method that may ensure representativeness of a sample. For our definition of probability to be consistent and accurate we must ensure two elements: Every person in the population has an equal chance of being selected Sampling occurs with replacement For random sampling a researcher starts with a complete list of the population (sometimes referred to as a sampling frame) and randomly selects some of them to an experiment. In this way every member of the population has an equal chance of being selected to participate. In order for the total number of outcomes to remain constant we need sampling with replacement  this means as one person is selected, another person must be added to keep the total number of possible outcomes the same. This is the full definition of random sampling. For example, if the population is 25 people, the sample is ten, and you are sampling with replacement for any particular sample, then the chance of picking the first person is ten out of 25, and the chance of picking a different second person is nine out of 25 (you replace the first person). If you sample without replacement, then the chance of picking the first person is ten out of 25, and then the chance of picking the second person (who is different) is nine out of 24 (you do not replace the first person). Compare the fractions to four decimal places: - 9/25 = 0.3600 - 9/24 = 0.3750 It is clear that these numbers are not equivalent. Since we are using small samples as a stand-in for large populations in a research experiment, there will always be a certain level of uncertainty in our conclusions. How do we know that calculating statistical probability gives us the right number? The answer to this question comes from the law of large numbers, which shows that the empirical probability will approach the true probability as the sample size increases. We can see this by simulating a large number of coin flips, and looking at our estimate of the probability of heads after each flip. The left panel of Figure 8 shows that as the number of samples (i.e., coin flip trials) increases, the estimated probability of heads converges onto the true value of 0.5. Its unlikely that any of us has ever flipped a coin tens of thousands of times, but we are nonetheless willing to believe that the probability of flipping heads is 0.5. However, note that the estimates can be very far off from the true value when the sample sizes are small. A real-world example of this was seen in the 2017 special election for the US Senate in Alabama, which pitted the Republican Roy Moore against Democrat Doug Jones. The right panel of Figure 8 shows the relative amount of the vote reported for each of the candidates over the course of the evening, as an increasing number of ballots were counted. Early in the evening the vote counts were especially volatile, swinging from a large initial lead for Jones to a long period where Moore had the lead, until finally Jones took the lead to win the race. Figure 1.7: Left: A demonstration of the law of large numbers. A coin was flipped 30,000 times, and after each flip the probability of heads was computed based on the number of heads and tail collected up to that point. It takes about 15,000 flips for the probability to settle at the true probability of 0.5. Right: Relative proportion of the vote in the Dec 12, 2017 special election for the US Senate seat in Alabama, as a function of the percentage of precincts reporting. These data were transcribed from here These two examples show that while large samples will ultimately converge on the true probability, the results with small samples can be far off. Unfortunately, many people forget this and overinterpret results from small samples. This was referred to as the law of small numbers by the psychologists Danny Kahneman and Amos Tversky, who showed that people (even trained researchers) often behave as if the law of large numbers applies even to small samples, giving too much credence to results based on small datasets. We will see examples throughout the course of just how unstable statistical results can be when they are generated on the basis of small samples. Furthermore, a very important point: even if we are able to make an accurate prediction, we can never prove with 100% certainty that this prediction will hold true in all possible situations. This is because samples never have exactly the same characteristics of the population from which they come from. Therefore, we will always have some level of uncertainty about whether the results found in our sample are also found in the population. The best we can do is infer what is most likely to be found. Our level of confidence in an inferential statistic or the outcome of an experiment is represented through probability theory. 1.5 More Probability Terms A probability distribution describes the probability of all of the possible outcomes in an activity. For example, on Jan 20 2018, the basketball player Steph Curry hit only 2 out of 4 free throws in a game against the Houston Rockets. We know that Currys overall probability of hitting free throws across the entire season was 0.91, so it seems pretty unlikely that he would hit only 50% of his free throws in a game, but exactly how unlikely is it? We can determine this using a theoretical probability distribution; throughout this book we will encounter a number of these probability distributions, each of which is appropriate to describe different types of data. In this case, we use the binomial distribution, which provides a way to compute the probability of some number of successes out of a number of trials on which there is either success or failure and nothing in between (only 2 outcomes), given some known probability of success on each trial. In this example, if we calculated the probability of Curry making 2 of 4 free throws when his season average was .91, it would come out to a 4% chance1. This shows that given Currys overall free throw percentage, it is very unlikely that he would hit only 2 out of 4 free throws. This just goes to show that unlikely things do actually happen in the real world. Often though, we might want to know how likely it is to find a value that is as extreme or more than a particular value versus a specific value; this will become very important when we discuss hypothesis testing later. To answer this question, we can use a cumulative probability distribution; whereas a standard probability distribution tells us the probability of some specific value, the cumulative distribution tells us the probability of a value as large or larger (or as small or smaller) than some specific value. For the Curry free-throw example, this would be .0432. In many cases the number of possible outcomes would be too large for us to compute the cumulative probability by enumerating all possible values; fortunately, it can be computed directly for any theoretical probability distribution. Although we have information, sometimes we can be mislead. Lets use the example of a coin toss. Each toss is independent of one another with only 2 outcomes {heads, tails}. What if I want to calculate the probability of getting heads for a coin toss? I might base that on my previous 12 coin flips. A coin might come up heads 8 times out of 12 flips, for a relative frequency of 8/12 or 2/3. Again, the probability is usually calculated as the proportion of successful outcomes divided by the number of all possible outcomes. What happens if I toss the coin again? What is the probability that it will be heads again? Do I use information from my previous 12 flips? Well, the answer is ½ or 50%. That is because in our scenario, each toss is independent and each outcome is independent. This means that the outcome of the ninth toss is not related to the previous toss. To assume otherwise is committing what we call gamblers fallacy. The term independent has a very specific meaning in statistics, which is somewhat different from the common usage of the term. Statistical independence between two variables means that knowing the value of one variable doesnt tell us anything about the value of the other. This can be expressed as: P(A|B)=P(A). That is, the probability of A given some value of B is just the same as the overall probability of A (because they are independent). Again, while independence in common language often refers to sets that are exclusive, statistical independence refers to the case where one cannot predict anything about one variable from the value of another variable. For example, knowing a persons hair color is unlikely to tell you whether they prefer chocolate or strawberry ice cream. Later in the book we will discuss statistical tools that will let us directly test whether two variables are independent. Sometimes we want to quantify the relation between probabilities more directly, which we can do by converting them into odds which express the relative likelihood of something happening or not. We can use odds to compare different probabilities, by computing what is called an odds ratio  which is exactly what it sounds like. For example, lets say that we want to know how much the positive test increases the individuals odds of having cancer. We can first compute the prior odds  that is, the odds before we knew that the person had tested positively. An odds ratio is an example of what we will later call an effect size, which is a way of quantifying how relatively large any particular statistical effect is. A final point relates to how probabilities have been interpreted. Historically, there have been two different ways that probabilities have been interpreted. The first (known as the frequentist interpretation) interprets probabilities in terms of long-run frequencies. For example, in the case of a coin flip, it would reflect the relative frequencies of heads in the long run after a large number of flips. While this interpretation might make sense for events that can be repeated many times like a coin flip, it makes less sense for events that will only happen once, like an individual persons life or a particular presidential election; and as the economist John Maynard Keynes famously said, In the long run, we are all dead. The other interpretation of probabilities (known as the Bayesian interpretation) is as a degree of belief in a particular proposition. If I were to ask you How likely is it that the US will return to the moon by 2040, you can provide an answer to this question based on your knowledge and beliefs, even though there are no relevant frequencies to compute a frequentist probability. One way that we often frame subjective probabilities is in terms of ones willingness to accept a particular gamble. For example, if you think that the probability of the US landing on the moon by 2040 is 0.1 (i.e. odds of 9 to 1), then that means that you should be willing to accept a gamble that would pay off with anything more than 9 to 1 odds if the event occurs. As we will see, these two different definitions of probability are very relevant to the two different ways that statisticians think about testing statistical hypotheses, which we will encounter in later chapters. The fine print calculating Steph Currys free throws probability: P(2;4,0.91)=(42)0.912(10.91)42=0.040  Fine print: To determine this, we could use the binomial probability equation and plug in all of the possible values of outcomes and add them together: P(k2)=P(k=2)+P(k=1)+P(k=0)=6e5+.002+.040=.043 P(k)= P(k=2) + P(k=1) + P(k=0) = 6e^{-5} + .002 + .040 = .043 "],["recap.html", "2 Recap 2.1 Learning objectives 2.2 Exercises", " 2 Recap Probability is a mathematical tool used to study randomness. It deals with the chance (the likelihood) of an event occurring. The theory of probability began with the study of games of chance such as poker. Predictions take the form of probabilities. To predict the likelihood of an earthquake, of rain, or whether you will get an A in this course, we use probabilities. Doctors use probability to determine the chance of a vaccination causing the disease the vaccination is supposed to prevent. A stockbroker uses probability to determine the rate of return on a clients investments. You might use probability to decide to buy a lottery ticket or not. In your study of statistics, you will use the power of mathematics through probability calculations to analyze and interpret your data. 2.1 Learning objectives Having read this chapter, you should be able to: Describe the sample space for a selected random experiment. Describe the law of large numbers. Describe the difference between a probability and a conditional probability Describe the relationship between z-scores and the standard unit normal table (z-table) Probability is a tough topic for everyone, but the tools it gives us are incredibly powerful and enable us to do amazing things with data analysis. They are the heart of how inferential statistics work. 2.2 Exercises In your own words, what is probability? There is a bag with 5 red blocks, 2 yellow blocks, and 4 blue blocks. If you reach in and grab one block without looking, what is the probability it is red? Under a normal distribution, which of the following is more likely? (Note: this question can be answered without any calculations if you draw out the distributions and shade properly) Getting a z-score greater than z = 2.75 Getting a z-score less than z = -1.50 The heights of women in the United States are normally distributed with a mean of 63.7 inches and a standard deviation of 2.7 inches. If you randomly select a woman in the United States, what is the probability that she will be between 65 and 67 inches tall? The heights of men in the United States are normally distributed with a mean of 69.1 inches and a standard deviation of 2.9 inches. 6. What proportion of men are taller than 6 feet (72 inches)? You know you need to score at least 82 points on the final exam to pass your class. After the final, you find out that the average score on the exam was 78 with a standard deviation of 7. How likely is it that you pass the class? What proportion of the area under the normal curve is greater than z = 1.65? Find the z-score that bounds 25% of the lower tail of the distribution. Find the z-score that bounds the top 9% of the distribution. In a distribution with a mean of 70 and standard deviation of 12, what proportion of scores are lower than 55? "],["probability.html", "3 Welcome to Sampling and some more on probability 3.1 How are probability and statistics different? 3.2 What does probability mean? 3.3 Basic probability theory 3.4 The binomial distribution 3.5 The normal distribution 3.6 Other useful distributions 3.7 Summary", " 3 Welcome to Sampling and some more on probability [God] has afforded us only the twilight  of Probability.  John Locke Up to this point, weve talked a little about how you can summarise a data set. To a lot of people, this is all there is to statistics: its about calculating averages, collecting all the numbers, drawing pictures, and putting them all in a report somewhere. Kind of like stamp collecting, but with numbers. However, statistics covers much more than that. In fact, descriptive statistics is one of the smallest parts of statistics, and one of the least powerful. The bigger and more useful part of statistics is that it provides tools that let you make inferences about data. Once you start thinking about statistics in these terms  that statistics is there to help us draw inferences from data  you start seeing examples of it everywhere. For instance, heres a tiny extract from a newspaper article in the Sydney Morning Herald (30 Oct 2010): I have a tough job, the Premier said in response to a poll which found her government is now the most unpopular Labor administration in polling history, with a primary vote of just 23 per cent. This kind of remark is entirely unremarkable in the papers or in everyday life, but lets have a think about what it entails. A polling company has conducted a survey, usually a pretty big one because they can afford it. Im too lazy to track down the original survey, so lets just imagine that they called 1000 NSW voters at random, and 230 (23%) of those claimed that they intended to vote for the ALP. For the 2010 Federal election, the Australian Electoral Commission reported 4,610,795 enrolled voters in NSW; so the opinions of the remaining 4,609,795 voters (about 99.98% of voters) remain unknown to us. Even assuming that no-one lied to the polling company the only thing we can say with 100% confidence is that the true ALP primary vote is somewhere between 230/4610795 (about 0.005%) and 4610025/4610795 (about 99.83%). So, on what basis is it legitimate for the polling company, the newspaper, and the readership to conclude that the ALP primary vote is only about 23%? The answer to the question is pretty obvious: if I call 1000 people at random, and 230 of them say they intend to vote for the ALP, then it seems very unlikely that these are the only 230 people out of the entire voting public who actually intend to do so. In other words, we assume that the data collected by the polling company is pretty representative of the population at large. But how representative? Would we be surprised to discover that the true ALP primary vote is actually 24%? 29%? 37%? At this point everyday intuition starts to break down a bit. No-one would be surprised by 24%, and everybody would be surprised by 37%, but its a bit hard to say whether 29% is plausible. We need some more powerful tools than just looking at the numbers and guessing. Inferential statistics provides the tools that we need to answer these sorts of questions, and since these kinds of questions lie at the heart of the scientific enterprise, they take up the lions share of every introductory course on statistics and research methods. However, the theory of statistical inference is built on top of probability theory. And it is to probability theory that we must now turn. This discussion of probability theory is basically background: theres not a lot of statistics per se in this chapter, and you dont need to understand this material in as much depth as the other chapters in this part of the book. Nevertheless, because probability theory does underpin so much of statistics, its worth covering some of the basics. 3.1 How are probability and statistics different? Before we start talking about probability theory, its helpful to spend a moment thinking about the relationship between probability and statistics. The two disciplines are closely related but theyre not identical. Probability theory is the doctrine of chances. Its a branch of mathematics that tells you how often different kinds of events will happen. For example, all of these questions are things you can answer using probability theory: What are the chances of a fair coin coming up heads 10 times in a row? If I roll two six sided dice, how likely is it that Ill roll two sixes? How likely is it that five cards drawn from a perfectly shuffled deck will all be hearts? What are the chances that Ill win the lottery? Notice that all of these questions have something in common. In each case the truth of the world is known, and my question relates to the what kind of events will happen. In the first question I know that the coin is fair, so theres a 50% chance that any individual coin flip will come up heads. In the second question, I know that the chance of rolling a 6 on a single die is 1 in 6. In the third question I know that the deck is shuffled properly. And in the fourth question, I know that the lottery follows specific rules. You get the idea. The critical point is that probabilistic questions start with a known model of the world, and we use that model to do some calculations. The underlying model can be quite simple. For instance, in the coin flipping example, we can write down the model like this: \\[ P(\\mbox{heads}) = 0.5 \\] which you can read as the probability of heads is 0.5. As well see later, in the same way that percentages are numbers that range from 0% to 100%, probabilities are just numbers that range from 0 to 1. When using this probability model to answer the first question, I dont actually know exactly whats going to happen. Maybe Ill get 10 heads, like the question says. But maybe Ill get three heads. Thats the key thing: in probability theory, the model is known, but the data are not. So thats probability. What about statistics? Statistical questions work the other way around. In statistics, we do not know the truth about the world. All we have is the data, and it is from the data that we want to learn the truth about the world. Statistical questions tend to look more like these: If my friend flips a coin 10 times and gets 10 heads, are they playing a trick on me? If five cards off the top of the deck are all hearts, how likely is it that the deck was shuffled? - If the lottery commissioners spouse wins the lottery, how likely is it that the lottery was rigged? This time around, the only thing we have are data. What I know is that I saw my friend flip the coin 10 times and it came up heads every time. And what I want to infer is whether or not I should conclude that what I just saw was actually a fair coin being flipped 10 times in a row, or whether I should suspect that my friend is playing a trick on me. The data I have look like this: H H H H H H H H H H H and what Im trying to do is work out which model of the world I should put my trust in. If the coin is fair, then the model I should adopt is one that says that the probability of heads is 0.5; that is, \\(P(\\mbox{heads}) = 0.5\\). If the coin is not fair, then I should conclude that the probability of heads is not 0.5, which we would write as \\(P(\\mbox{heads}) \\neq 0.5\\). In other words, the statistical inference problem is to figure out which of these probability models is right. Clearly, the statistical question isnt the same as the probability question, but theyre deeply connected to one another. Because of this, a good introduction to statistical theory will start with a discussion of what probability is and how it works. 3.2 What does probability mean? Lets start with the first of these questions. What is probability? It might seem surprising to you, but while statisticians and mathematicians (mostly) agree on what the rules of probability are, theres much less of a consensus on what the word really means. It seems weird because were all very comfortable using words like chance, likely, possible and probable, and it doesnt seem like it should be a very difficult question to answer. If you had to explain probability to a five year old, you could do a pretty good job. But if youve ever had that experience in real life, you might walk away from the conversation feeling like you didnt quite get it right, and that (like many everyday concepts) it turns out that you dont really know what its all about. So Ill have a go at it. Lets suppose I want to bet on a soccer game between two teams of robots, Arduino Arsenal and C Milan. After thinking about it, I decide that there is an 80% probability that Arduino Arsenal winning. What do I mean by that? Here are three possibilities Theyre robot teams, so I can make them play over and over again, and if I did that, Arduino Arsenal would win 8 out of every 10 games on average. For any given game, I would only agree that betting on this game is only fair if a $1 bet on C Milan gives a $5 payoff (i.e. I get my $1 back plus a $4 reward for being correct), as would a $4 bet on Arduino Arsenal (i.e., my $4 bet plus a $1 reward). My subjective belief or confidence in an Arduino Arsenal victory is four times as strong as my belief in a C Milan victory. Each of these seems sensible. However theyre not identical, and not every statistician would endorse all of them. The reason is that there are different statistical ideologies (yes, really!) and depending on which one you subscribe to, you might say that some of those statements are meaningless or irrelevant. In this section, I give a brief introduction the two main approaches that exist in the literature. These are by no means the only approaches, but theyre the two big ones. 3.2.1 The frequentist view The first of the two major approaches to probability, and the more dominant one in statistics, is referred to as the frequentist view, and it defines probability as a long-run frequency. Suppose we were to try flipping a fair coin, over and over again. By definition, this is a coin that has \\(P(H) = 0.5\\). What might we observe? One possibility is that the first 20 flips might look like this: T,H,H,H,H,T,T,H,H,H,H,T,H,H,T,T,T,T,T,H In this case 11 of these 20 coin flips (55%) came up heads. Now suppose that Id been keeping a running tally of the number of heads (which Ill call \\(N_H\\)) that Ive seen, across the first \\(N\\) flips, and calculate the proportion of heads \\(N_H / N\\) every time. Heres what Id get (I did literally flip coins to produce this!): number.of.flips number.of.heads proportion 1 0 0.00 2 1 0.50 3 2 0.67 4 3 0.75 5 4 0.80 6 4 0.67 7 4 0.57 8 5 0.63 9 6 0.67 10 7 0.70 11 8 0.73 12 8 0.67 13 9 0.69 14 10 0.71 15 10 0.67 16 10 0.63 17 10 0.59 18 10 0.56 19 10 0.53 20 11 0.55 Notice that at the start of the sequence, the proportion of heads fluctuates wildly, starting at .00 and rising as high as .80. Later on, one gets the impression that it dampens out a bit, with more and more of the values actually being pretty close to the right answer of .50. This is the frequentist definition of probability in a nutshell: flip a fair coin over and over again, and as \\(N\\) grows large (approaches infinity, denoted \\(N\\rightarrow \\infty\\)), the proportion of heads will converge to 50%. There are some subtle technicalities that the mathematicians care about, but qualitatively speaking, thats how the frequentists define probability. Unfortunately, I dont have an infinite number of coins, or the infinite patience required to flip a coin an infinite number of times. However, I do have a computer, and computers excel at mindless repetitive tasks. So I asked my computer to simulate flipping a coin 1000 times, and then drew a picture of what happens to the proportion \\(N_H / N\\) as \\(N\\) increases. Actually, I did it four times, just to make sure it wasnt a fluke. The results are shown in Figure 3.1. As you can see, the proportion of observed heads eventually stops fluctuating, and settles down; when it does, the number at which it finally settles is the true probability of heads. Figure 3.1: An illustration of how frequentist probability works. If you flip a fair coin over and over again, the proportion of heads that youve seen eventually settles down, and converges to the true probability of 0.5. Each panel shows four different simulated experiments: in each case, we pretend we flipped a coin 1000 times, and kept track of the proportion of flips that were heads as we went along. Although none of these sequences actually ended up with an exact value of .5, if wed extended the experiment for an infinite number of coin flips they would have. The frequentist definition of probability has some desirable characteristics. Firstly, it is objective: the probability of an event is necessarily grounded in the world. The only way that probability statements can make sense is if they refer to (a sequence of) events that occur in the physical universe.3 Secondly, it is unambiguous: any two people watching the same sequence of events unfold, trying to calculate the probability of an event, must inevitably come up with the same answer. However, it also has undesirable characteristics. Firstly, infinite sequences dont exist in the physical world. Suppose you picked up a coin from your pocket and started to flip it. Every time it lands, it impacts on the ground. Each impact wears the coin down a bit; eventually, the coin will be destroyed. So, one might ask whether it really makes sense to pretend that an infinite sequence of coin flips is even a meaningful concept, or an objective one. We cant say that an infinite sequence of events is a real thing in the physical universe, because the physical universe doesnt allow infinite anything. More seriously, the frequentist definition has a narrow scope. There are lots of things out there that human beings are happy to assign probability to in everyday language, but cannot (even in theory) be mapped onto a hypothetical sequence of events. For instance, if a meteorologist comes on TV and says, the probability of rain in Adelaide on 2 November 2048 is 60% we humans are happy to accept this. But its not clear how to define this in frequentist terms. Theres only one city of Adelaide, and only 2 November 2048. Theres no infinite sequence of events here, just a once-off thing. Frequentist probability genuinely forbids us from making probability statements about a single event. From the frequentist perspective, it will either rain tomorrow or it will not; there is no probability that attaches to a single non-repeatable event. Now, it should be said that there are some very clever tricks that frequentists can use to get around this. One possibility is that what the meteorologist means is something like this: There is a category of days for which I predict a 60% chance of rain; if we look only across those days for which I make this prediction, then on 60% of those days it will actually rain. Its very weird and counterintuitive to think of it this way, but you do see frequentists do this sometimes. And it will come up later in this book (see Section ??). 3.2.2 The Bayesian view The Bayesian view of probability is often called the subjectivist view, and it is a minority view among statisticians, but one that has been steadily gaining traction for the last several decades. There are many flavours of Bayesianism, making hard to say exactly what the Bayesian view is. The most common way of thinking about subjective probability is to define the probability of an event as the degree of belief that an intelligent and rational agent assigns to that truth of that event. From that perspective, probabilities dont exist in the world, but rather in the thoughts and assumptions of people and other intelligent beings. However, in order for this approach to work, we need some way of operationalising degree of belief. One way that you can do this is to formalise it in terms of rational gambling, though there are many other ways. Suppose that I believe that theres a 60% probability of rain tomorrow. If someone offers me a bet: if it rains tomorrow, then I win $5, but if it doesnt rain then I lose $5. Clearly, from my perspective, this is a pretty good bet. On the other hand, if I think that the probability of rain is only 40%, then its a bad bet to take. Thus, we can operationalise the notion of a subjective probability in terms of what bets Im willing to accept. What are the advantages and disadvantages to the Bayesian approach? The main advantage is that it allows you to assign probabilities to any event you want to. You dont need to be limited to those events that are repeatable. The main disadvantage (to many people) is that we cant be purely objective  specifying a probability requires us to specify an entity that has the relevant degree of belief. This entity might be a human, an alien, a robot, or even a statistician, but there has to be an intelligent agent out there that believes in things. To many people this is uncomfortable: it seems to make probability arbitrary. While the Bayesian approach does require that the agent in question be rational (i.e., obey the rules of probability), it does allow everyone to have their own beliefs; I can believe the coin is fair and you dont have to, even though were both rational. The frequentist view doesnt allow any two observers to attribute different probabilities to the same event: when that happens, then at least one of them must be wrong. The Bayesian view does not prevent this from occurring. Two observers with different background knowledge can legitimately hold different beliefs about the same event. In short, where the frequentist view is sometimes considered to be too narrow (forbids lots of things that that we want to assign probabilities to), the Bayesian view is sometimes thought to be too broad (allows too many differences between observers). 3.2.3 Whats the difference? And who is right? Now that youve seen each of these two views independently, its useful to make sure you can compare the two. Go back to the hypothetical robot soccer game at the start of the section. What do you think a frequentist and a Bayesian would say about these three statements? Which statement would a frequentist say is the correct definition of probability? Which one would a Bayesian do? Would some of these statements be meaningless to a frequentist or a Bayesian? If youve understood the two perspectives, you should have some sense of how to answer those questions. Okay, assuming you understand the different, you might be wondering which of them is right? Honestly, I dont know that there is a right answer. As far as I can tell theres nothing mathematically incorrect about the way frequentists think about sequences of events, and theres nothing mathematically incorrect about the way that Bayesians define the beliefs of a rational agent. In fact, when you dig down into the details, Bayesians and frequentists actually agree about a lot of things. Many frequentist methods lead to decisions that Bayesians agree a rational agent would make. Many Bayesian methods have very good frequentist properties. For the most part, Im a pragmatist so Ill use any statistical method that I trust. As it turns out, that makes me prefer Bayesian methods, for reasons Ill explain towards the end of the book, but Im not fundamentally opposed to frequentist methods. Not everyone is quite so relaxed. For instance, consider Sir Ronald Fisher, one of the towering figures of 20th century statistics and a vehement opponent to all things Bayesian, whose paper on the mathematical foundations of statistics referred to Bayesian probability as an impenetrable jungle [that] arrests progress towards precision of statistical concepts (Fisher1922b?). Or the psychologist Paul Meehl, who suggests that relying on frequentist methods could turn you into a potent but sterile intellectual rake who leaves in his merry path a long train of ravished maidens but no viable scientific offspring (Meehl1967?). The history of statistics, as you might gather, is not devoid of entertainment. In any case, while I personally prefer the Bayesian view, the majority of statistical analyses are based on the frequentist approach. My reasoning is pragmatic: the goal of this book is to cover roughly the same territory as a typical undergraduate stats class in psychology, and if you want to understand the statistical tools used by most psychologists, youll need a good grasp of frequentist methods. I promise you that this isnt wasted effort. Even if you end up wanting to switch to the Bayesian perspective, you really should read through at least one book on the orthodox frequentist view. And since R is the most widely used statistical language for Bayesians, you might as well read a book that uses R. Besides, I wont completely ignore the Bayesian perspective. Every now and then Ill add some commentary from a Bayesian point of view, and Ill revisit the topic in more depth in Chapter ??. 3.3 Basic probability theory Ideological arguments between Bayesians and frequentists notwithstanding, it turns out that people mostly agree on the rules that probabilities should obey. There are lots of different ways of arriving at these rules. The most commonly used approach is based on the work of Andrey Kolmogorov, one of the great Soviet mathematicians of the 20th century. I wont go into a lot of detail, but Ill try to give you a bit of a sense of how it works. And in order to do so, Im going to have to talk about my pants. 3.3.1 Introducing probability distributions One of the disturbing truths about my life is that I only own 5 pairs of pants: three pairs of jeans, the bottom half of a suit, and a pair of tracksuit pants. Even sadder, Ive given them names: I call them \\(X_1\\), \\(X_2\\), \\(X_3\\), \\(X_4\\) and \\(X_5\\). I really do: thats why they call me Mister Imaginative. Now, on any given day, I pick out exactly one of pair of pants to wear. Not even Im so stupid as to try to wear two pairs of pants, and thanks to years of training I never go outside without wearing pants anymore. If I were to describe this situation using the language of probability theory, I would refer to each pair of pants (i.e., each \\(X\\)) as an elementary event. The key characteristic of elementary events is that every time we make an observation (e.g., every time I put on a pair of pants), then the outcome will be one and only one of these events. Like I said, these days I always wear exactly one pair of pants, so my pants satisfy this constraint. Similarly, the set of all possible events is called a sample space. Granted, some people would call it a wardrobe, but thats because theyre refusing to think about my pants in probabilistic terms. Sad. Okay, now that we have a sample space (a wardrobe), which is built from lots of possible elementary events (pants), what we want to do is assign a probability of one of these elementary events. For an event \\(X\\), the probability of that event \\(P(X)\\) is a number that lies between 0 and 1. The bigger the value of \\(P(X)\\), the more likely the event is to occur. So, for example, if \\(P(X) = 0\\), it means the event \\(X\\) is impossible (i.e., I never wear those pants). On the other hand, if \\(P(X) = 1\\) it means that event \\(X\\) is certain to occur (i.e., I always wear those pants). For probability values in the middle, it means that I sometimes wear those pants. For instance, if \\(P(X) = 0.5\\) it means that I wear those pants half of the time. At this point, were almost done. The last thing we need to recognise is that something always happens. Every time I put on pants, I really do end up wearing pants (crazy, right?). What this somewhat trite statement means, in probabilistic terms, is that the probabilities of the elementary events need to add up to 1. This is known as the law of total probability, not that any of us really care. More importantly, if these requirements are satisfied, then what we have is a probability distribution. For example, this is an example of a probability distribution Which.pants Blue.jeans Grey.jeans Black.jeans Black.suit Blue.tracksuit Label \\(X_1\\) \\(X_2\\) \\(X_3\\) \\(X_4\\) \\(X_5\\) Probability \\(P(X_1) = .5\\) \\(P(X_2) = .3\\) \\(P(X_3) = .1\\) \\(P(X_4) = 0\\) \\(P(X_5) = .1\\) Each of the events has a probability that lies between 0 and 1, and if we add up the probability of all events, they sum to 1. Awesome. We can even draw a nice bar graph (see Section ??) to visualise this distribution, as shown in Figure 3.2. And at this point, weve all achieved something. Youve learned what a probability distribution is, and Ive finally managed to find a way to create a graph that focuses entirely on my pants. Everyone wins! Figure 3.2: A visual depiction of the pants probability distribution. There are five elementary events, corresponding to the five pairs of pants that I own. Each event has some probability of occurring: this probability is a number between 0 to 1. The sum of these probabilities is 1. The only other thing that I need to point out is that probability theory allows you to talk about non elementary events as well as elementary ones. The easiest way to illustrate the concept is with an example. In the pants example, its perfectly legitimate to refer to the probability that I wear jeans. In this scenario, the Dan wears jeans event said to have happened as long as the elementary event that actually did occur is one of the appropriate ones; in this case blue jeans, black jeans or grey jeans. In mathematical terms, we defined the jeans event \\(E\\) to correspond to the set of elementary events \\((X_1, X_2, X_3)\\). If any of these elementary events occurs, then \\(E\\) is also said to have occurred. Having decided to write down the definition of the \\(E\\) this way, its pretty straightforward to state what the probability \\(P(E)\\) is: we just add everything up. In this particular case \\[ P(E) = P(X_1) + P(X_2) + P(X_3) \\] and, since the probabilities of blue, grey and black jeans respectively are .5, .3 and .1, the probability that I wear jeans is equal to .9. At this point you might be thinking that this is all terribly obvious and simple and youd be right. All weve really done is wrap some basic mathematics around a few common sense intuitions. However, from these simple beginnings its possible to construct some extremely powerful mathematical tools. Im definitely not going to go into the details in this book, but what I will do is list  in Table 3.1  some of the other rules that probabilities satisfy. These rules can be derived from the simple assumptions that Ive outlined above, but since we dont actually use these rules for anything in this book, I wont do so here. Table 3.1: Some basic rules that probabilities must satisfy. You dont really need to know these rules in order to understand the analyses that well talk about later in the book, but they are important if you want to understand probability theory a bit more deeply. English Notation NANA Formula Not \\(A\\) \\(P(\\neg A)\\) = \\(1-P(A)\\) \\(A\\) or \\(B\\) \\(P(A \\cup B)\\) = \\(P(A) + P(B) - P(A \\cap B)\\) \\(A\\) and \\(B\\) \\(P(A \\cap B)\\) = \\(P(A&amp;#124;B) P(B)\\) 3.4 The binomial distribution As you might imagine, probability distributions vary enormously, and theres an enormous range of distributions out there. However, they arent all equally important. In fact, the vast majority of the content in this book relies on one of five distributions: the binomial distribution, the normal distribution, the \\(t\\) distribution, the \\(\\chi^2\\) (chi-square) distribution and the \\(F\\) distribution. Given this, what Ill do over the next few sections is provide a brief introduction to all five of these, paying special attention to the binomial and the normal. Ill start with the binomial distribution, since its the simplest of the five. 3.4.1 Introducing the binomial The theory of probability originated in the attempt to describe how games of chance work, so it seems fitting that our discussion of the binomial distribution should involve a discussion of rolling dice and flipping coins. Lets imagine a simple experiment: in my hot little hand Im holding 20 identical six-sided dice. On one face of each die theres a picture of a skull; the other five faces are all blank. If I proceed to roll all 20 dice, whats the probability that Ill get exactly 4 skulls? Assuming that the dice are fair, we know that the chance of any one die coming up skulls is 1 in 6; to say this another way, the skull probability for a single die is approximately \\(.167\\). This is enough information to answer our question, so lets have a look at how its done. As usual, well want to introduce some names and some notation. Well let \\(N\\) denote the number of dice rolls in our experiment; which is often referred to as the size parameter of our binomial distribution. Well also use \\(\\theta\\) to refer to the the probability that a single die comes up skulls, a quantity that is usually called the success probability of the binomial.4 Finally, well use \\(X\\) to refer to the results of our experiment, namely the number of skulls I get when I roll the dice. Since the actual value of \\(X\\) is due to chance, we refer to it as a random variable. In any case, now that we have all this terminology and notation, we can use it to state the problem a little more precisely. The quantity that we want to calculate is the probability that \\(X = 4\\) given that we know that \\(\\theta = .167\\) and \\(N=20\\). The general form of the thing Im interested in calculating could be written as \\[ P(X \\ | \\ \\theta, N) \\] and were interested in the special case where \\(X=4\\), \\(\\theta = .167\\) and \\(N=20\\). Theres only one more piece of notation I want to refer to before moving on to discuss the solution to the problem. If I want to say that \\(X\\) is generated randomly from a binomial distribution with parameters \\(\\theta\\) and \\(N\\), the notation I would use is as follows: \\[ X \\sim \\mbox{Binomial}(\\theta, N) \\] Yeah, yeah. I know what youre thinking: notation, notation, notation. Really, who cares? Very few readers of this book are here for the notation, so I should probably move on and talk about how to use the binomial distribution. Ive included the formula for the binomial distribution in Table 3.2, since some readers may want to play with it themselves, but since most people probably dont care that much and because we dont need the formula in this book, I wont talk about it in any detail. Instead, I just want to show you what the binomial distribution looks like. To that end, Figure 3.3 plots the binomial probabilities for all possible values of \\(X\\) for our dice rolling experiment, from \\(X=0\\) (no skulls) all the way up to \\(X=20\\) (all skulls). Note that this is basically a bar chart, and is no different to the pants probability plot I drew in Figure 3.2. On the horizontal axis we have all the possible events, and on the vertical axis we can read off the probability of each of those events. So, the probability of rolling 4 skulls out of 20 times is about 0.20 (the actual answer is 0.2022036, as well see in a moment). In other words, youd expect that to happen about 20% of the times you repeated this experiment. Table 3.2: Formulas for the binomial and normal distributions. We dont really use these formulas for anything in this book, but theyre pretty important for more advanced work, so I thought it might be best to put them here in a table, where they cant get in the way of the text. In the equation for the binomial, \\(X!\\) is the factorial function (i.e., multiply all whole numbers from 1 to \\(X\\)), and for the normal distribution exp refers to the exponential function, which we discussed in the Chapter on Data Handling. If these equations dont make a lot of sense to you, dont worry too much about them. Binomial Normal \\(P(X &amp;#124; \\theta, N) = \\displaystyle\\frac{N!}{X! (N-X)!} \\theta^X (1-\\theta)^{N-X}\\) \\(p(X &amp;#124; \\mu, \\sigma) = \\displaystyle\\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp \\left( -\\frac{(X - \\mu)^2}{2\\sigma^2} \\right)\\) Figure 3.3: The binomial distribution with size parameter of \\(N=20\\) and an underlying success probability of \\(theta = 1/6\\). Each vertical bar depicts the probability of one specific outcome (i.e., one possible value of \\(X\\)). Because this is a probability distribution, each of the probabilities must be a number between 0 and 1, and the heights of the bars must sum to 1 as well. 3.4.2 Working with the binomial distribution in R Although some people find it handy to know the formulas in Table 3.2, most people just want to know how to use the distributions without worrying too much about the maths. To that end, R has a function called dbinom() that calculates binomial probabilities for us. The main arguments to the function are x. This is a number, or vector of numbers, specifying the outcomes whose probability youre trying to calculate. size. This is a number telling R the size of the experiment. prob. This is the success probability for any one trial in the experiment. So, in order to calculate the probability of getting x = 4 skulls, from an experiment of size = 20 trials, in which the probability of getting a skull on any one trial is prob = 1/6  well, the command I would use is simply this: dbinom( x = 4, size = 20, prob = 1/6 ) #&gt; [1] 0.202 To give you a feel for how the binomial distribution changes when we alter the values of \\(\\theta\\) and \\(N\\), lets suppose that instead of rolling dice, Im actually flipping coins. This time around, my experiment involves flipping a fair coin repeatedly, and the outcome that Im interested in is the number of heads that I observe. In this scenario, the success probability is now \\(\\theta = 1/2\\). Suppose I were to flip the coin \\(N=20\\) times. In this example, Ive changed the success probability, but kept the size of the experiment the same. What does this do to our binomial distribution? Well, as Figure 3.4 shows, the main effect of this is to shift the whole distribution, as youd expect. Okay, what if we flipped a coin \\(N=100\\) times? Well, in that case, we get Figure 3.5. The distribution stays roughly in the middle, but theres a bit more variability in the possible outcomes. Figure 3.4: Two binomial distributions, involving a scenario in which Im flipping a fair coin, so the underlying success probability is \\(theta = 1/2\\). Here we assume Im flipping the coin \\(N=20\\) times. Figure 3.5: Two binomial distributions, involving a scenario in which Im flipping a fair coin, so the underlying success probability is \\(theta = 1/2\\). Here we assume that the coin is flipped \\(N=100\\) times. At this point, I should probably explain the name of the dbinom() function. Obviously, the binom part comes from the fact that were working with the binomial distribution, but the d prefix is probably a bit of a mystery. In this section Ill give a partial explanation: specifically, Ill explain why there is a prefix. As for why its a d specifically, youll have to wait until the next section. Whats going on here is that R actually provides four functions in relation to the binomial distribution. These four functions are dbinom(), pbinom(), rbinom() and qbinom(), and each one calculates a different quantity of interest. Not only that, R does the same thing for every probability distribution that it implements. No matter what distribution youre talking about, theres a d function, a p function, a q function and a r function. This is illustrated in Table 3.3, using the binomial distribution and the normal distribution as examples. Table 3.3: The naming system for R probability distribution functions. Every probability distribution implemented in R is actually associated with four separate functions, and there is a pretty standardised way for naming these functions. What.it.does Prefix Normal.distribution Binomial.distribution probability (density) of d dnorm() dbinom() cumulative probability of p dnorm() pbinom() generate random number from r rnorm() rbinom() q qnorm() qbinom() q qnorm() qbinom( Lets have a look at what all four functions do. Firstly, all four versions of the function require you to specify the size and prob arguments: no matter what youre trying to get R to calculate, it needs to know what the parameters are. However, they differ in terms of what the other argument is, and what the output is. So lets look at them one at a time. The d form weve already seen: you specify a particular outcome x, and the output is the probability of obtaining exactly that outcome. (the d is short for density, but ignore that for now). The p form calculates the cumulative probability. You specify a particular quantile q, and it tells you the probability of obtaining an outcome smaller than or equal to q. The q form calculates the quantiles of the distribution. You specify a probability value p, and gives you the corresponding percentile. That is, the value of the variable for which theres a probability p of obtaining an outcome lower than that value. The r form is a random number generator: specifically, it generates n random outcomes from the distribution. This is a little abstract, so lets look at some concrete examples. Again, weve already covered dbinom() so lets focus on the other three versions. Well start with pbinom(), and well go back to the skull-dice example. Again, Im rolling 20 dice, and each die has a 1 in 6 chance of coming up skulls. Suppose, however, that I want to know the probability of rolling 4 or fewer skulls. If I wanted to, I could use the dbinom() function to calculate the exact probability of rolling 0 skulls, 1 skull, 2 skulls, 3 skulls and 4 skulls and then add these up, but theres a faster way. Instead, I can calculate this using the pbinom() function. Heres the command: pbinom( q= 4, size = 20, prob = 1/6) #&gt; [1] 0.769 In other words, there is a 76.9% chance that I will roll 4 or fewer skulls. Or, to put it another way, R is telling us that a value of 4 is actually the 76.9th percentile of this binomial distribution. Next, lets consider the qbinom() function. Lets say I want to calculate the 75th percentile of the binomial distribution. If were sticking with our skulls example, I would use the following command to do this: qbinom( p = 0.75, size = 20, prob = 1/6) #&gt; [1] 4 Hm. Theres something odd going on here. Lets think this through. What the qbinom() function appears to be telling us is that the 75th percentile of the binomial distribution is 4, even though we saw from the pbinom() function that 4 is actually the 76.9th percentile. And its definitely the pbinom() function that is correct. I promise. The weirdness here comes from the fact that our binomial distribution doesnt really have a 75th percentile. Not really. Why not? Well, theres a 56.7% chance of rolling 3 or fewer skulls (you can type pbinom(3, 20, 1/6) to confirm this if you want), and a 76.9% chance of rolling 4 or fewer skulls. So theres a sense in which the 75th percentile should lie in between 3 and 4 skulls. But that makes no sense at all! You cant roll 20 dice and get 3.9 of them come up skulls. This issue can be handled in different ways: you could report an in between value (or interpolated value, to use the technical name) like 3.9, you could round down (to 3) or you could round up (to 4). The qbinom() function rounds upwards: if you ask for a percentile that doesnt actually exist (like the 75th in this example), R finds the smallest value for which the the percentile rank is at least what you asked for. In this case, since the true 75th percentile (whatever that would mean) lies somewhere between 3 and 4 skulls, R rounds up and gives you an answer of 4. This subtlety is tedious, I admit, but thankfully its only an issue for discrete distributions like the binomial (see Section ?? for a discussion of continuous versus discrete). The other distributions that Ill talk about (normal, \\(t\\), \\(\\chi^2\\) and \\(F\\)) are all continuous, and so R can always return an exact quantile whenever you ask for it. Finally, we have the random number generator. To use the rbinom() function, you specify how many times R should simulate the experiment using the n argument, and it will generate random outcomes from the binomial distribution. So, for instance, suppose I were to repeat my die rolling experiment 100 times. I could get R to simulate the results of these experiments by using the following command: rbinom( n = 100, size = 20, prob = 1/6 ) #&gt; [1] 1 3 3 5 1 4 4 3 2 4 4 3 2 6 1 5 2 3 5 2 4 2 5 6 4 5 4 4 2 4 3 5 4 2 3 3 3 #&gt; [38] 3 8 5 2 4 3 4 4 2 0 4 1 2 5 5 4 7 2 7 8 4 6 7 7 3 2 3 5 1 4 5 5 4 4 4 3 0 #&gt; [75] 3 3 4 3 3 1 4 1 5 2 3 3 0 4 3 1 2 3 5 2 5 1 4 4 3 2 As you can see, these numbers are pretty much what youd expect given the distribution shown in Figure 3.3. Most of the time I roll somewhere between 1 to 5 skulls. There are a lot of subtleties associated with random number generation using a computer,5 but for the purposes of this book we dont need to worry too much about them. 3.5 The normal distribution While the binomial distribution is conceptually the simplest distribution to understand, its not the most important one. That particular honour goes to the normal distribution, which is also referred to as the bell curve or a Gaussian distribution. A normal distribution is described using two parameters, the mean of the distribution \\(\\mu\\) and the standard deviation of the distribution \\(\\sigma\\). The notation that we sometimes use to say that a variable \\(X\\) is normally distributed is as follows: \\[ X \\sim \\mbox{Normal}(\\mu,\\sigma) \\] Of course, thats just notation. It doesnt tell us anything interesting about the normal distribution itself. As was the case with the binomial distribution, I have included the formula for the normal distribution in this book, because I think its important enough that everyone who learns statistics should at least look at it, but since this is an introductory text I dont want to focus on it, so Ive tucked it away in Table 3.2. Similarly, the R functions for the normal distribution are dnorm(), pnorm(), qnorm() and rnorm(). However, they behave in pretty much exactly the same way as the corresponding functions for the binomial distribution, so theres not a lot that you need to know. The only thing that I should point out is that the argument names for the parameters are mean and sd. In pretty much every other respect, theres nothing else to add. Instead of focusing on the maths, lets try to get a sense for what it means for a variable to be normally distributed. To that end, have a look at Figure 3.6, which plots a normal distribution with mean \\(\\mu = 0\\) and standard deviation \\(\\sigma = 1\\). You can see where the name bell curve comes from: it looks a bit like a bell. Notice that, unlike the plots that I drew to illustrate the binomial distribution, the picture of the normal distribution in Figure 3.6 shows a smooth curve instead of histogram-like bars. This isnt an arbitrary choice: the normal distribution is continuous, whereas the binomial is discrete. For instance, in the die rolling example from the last section, it was possible to get 3 skulls or 4 skulls, but impossible to get 3.9 skulls. The figures that I drew in the previous section reflected this fact: in Figure 3.3, for instance, theres a bar located at \\(X=3\\) and another one at \\(X=4\\), but theres nothing in between. Continuous quantities dont have this constraint. For instance, suppose were talking about the weather. The temperature on a pleasant Spring day could be 23 degrees, 24 degrees, 23.9 degrees, or anything in between since temperature is a continuous variable, and so a normal distribution might be quite appropriate for describing Spring temperatures.6 Figure 3.6: The normal distribution with mean \\(mu = 0\\) and standard deviation \\(sigma = 1\\). The \\(x\\)-axis corresponds to the value of some variable, and the \\(y\\)-axis tells us something about how likely we are to observe that value. However, notice that the \\(y\\)-axis is labelled Probability Density and not Probability. There is a subtle and somewhat frustrating characteristic of continuous distributions that makes the \\(y\\) axis behave a bit oddly: the height of the curve here isnt actually the probability of observing a particular \\(x\\) value. On the other hand, it is true that the heights of the curve tells you which \\(x\\) values are more likely (the higher ones!). With this in mind, lets see if we cant get an intuition for how the normal distribution works. Firstly, lets have a look at what happens when we play around with the parameters of the distribution. To that end, Figure 3.7 plots normal distributions that have different means, but have the same standard deviation. As you might expect, all of these distributions have the same width. The only difference between them is that theyve been shifted to the left or to the right. In every other respect theyre identical. In contrast, if we increase the standard deviation while keeping the mean constant, the peak of the distribution stays in the same place, but the distribution gets wider, as you can see in Figure 3.8. Notice, though, that when we widen the distribution, the height of the peak shrinks. This has to happen: in the same way that the heights of the bars that we used to draw a discrete binomial distribution have to sum to 1, the total area under the curve for the normal distribution must equal 1. Figure 3.7: An illustration of what happens when you change the mean of a normal distribution. The solid line depicts a normal distribution with a mean of \\(mu=4\\). The dashed line shows a normal distribution with a mean of \\(mu=7\\). In both cases, the standard deviation is \\(sigma=1\\). Not surprisingly, the two distributions have the same shape, but the dashed line is shifted to the right. Figure 3.8: An illustration of what happens when you change the the standard deviation of a normal distribution. Both distributions plotted in this figure have a mean of \\(mu = 5\\), but they have different standard deviations. The solid line plots a distribution with standard deviation \\(sigma=1\\), and the dashed line shows a distribution with standard deviation \\(sigma = 2\\). As a consequence, both distributions are centred on the same spot, but the dashed line is wider than the solid one. Before moving on, I want to point out one important characteristic of the normal distribution. Irrespective of what the actual mean and standard deviation are, 68.3% of the area falls within 1 standard deviation of the mean. Similarly, 95.4% of the distribution falls within 2 standard deviations of the mean, and 99.7% of the distribution is within 3 standard deviations. This idea is illustrated in Figures 3.9 and 3.10. Figure 3.9: The area under the curve tells you the probability that an observation falls within a particular range. The solid lines plot normal distributions with mean \\(mu=0\\) and standard deviation \\(sigma=1\\) The shaded areas illustrate areas under the curve for two important cases. On the left, we can see that there is a 68.3% chance that an observation will fall within one standard deviation of the mean. On the right, we see that there is a 95.4% chance that an observation will fall within two standard deviations of the mean Figure 3.10: Two more examples of the area under the curve idea. There is a 15.9% chance that an observation is one standard deviation below the mean or smaller (left), and a 34.1% chance that the observation is greater than one standard deviation below the mean but still below the mean (right). Notice that if you add these two numbers together you get 15.9% + 34.1% = 50%. For normally distributed data, there is a 50% chance that an observation falls below the mean. And of course that also implies that there is a 50% chance that it falls above the mean. 3.5.1 Probability density Theres something Ive been trying to hide throughout my discussion of the normal distribution, something that some introductory textbooks omit completely. They might be right to do so: this thing that Im hiding is weird and counterintuitive even by the admittedly distorted standards that apply in statistics. Fortunately, its not something that you need to understand at a deep level in order to do basic statistics: rather, its something that starts to become important later on when you move beyond the basics. So, if it doesnt make complete sense, dont worry: try to make sure that you follow the gist of it. Throughout my discussion of the normal distribution, theres been one or two things that dont quite make sense. Perhaps you noticed that the \\(y\\)-axis in these figures is labelled Probability Density rather than density. Maybe you noticed that I used \\(p(X)\\) instead of \\(P(X)\\) when giving the formula for the normal distribution. Maybe youre wondering why R uses the d prefix for functions like dnorm(). And maybe, just maybe, youve been playing around with the dnorm() function, and you accidentally typed in a command like this: dnorm( x = 1, mean = 1, sd = 0.1 ) #&gt; [1] 3.99 And if youve done the last part, youre probably very confused. Ive asked R to calculate the probability that x = 1, for a normally distributed variable with mean = 1 and standard deviation sd = 0.1; and it tells me that the probability is 3.99. But, as we discussed earlier, probabilities cant be larger than 1. So either Ive made a mistake, or thats not a probability. As it turns out, the second answer is correct. What weve calculated here isnt actually a probability: its something else. To understand what that something is, you have to spend a little time thinking about what it really means to say that \\(X\\) is a continuous variable. Lets say were talking about the temperature outside. The thermometer tells me its 23 degrees, but I know thats not really true. Its not exactly 23 degrees. Maybe its 23.1 degrees, I think to myself. But I know that thats not really true either, because it might actually be 23.09 degrees. But, I know that well, you get the idea. The tricky thing with genuinely continuous quantities is that you never really know exactly what they are. Now think about what this implies when we talk about probabilities. Suppose that tomorrows maximum temperature is sampled from a normal distribution with mean 23 and standard deviation 1. Whats the probability that the temperature will be exactly 23 degrees? The answer is zero, or possibly, a number so close to zero that it might as well be zero. Why is this? Its like trying to throw a dart at an infinitely small dart board: no matter how good your aim, youll never hit it. In real life youll never get a value of exactly 23. Itll always be something like 23.1 or 22.99998 or something. In other words, its completely meaningless to talk about the probability that the temperature is exactly 23 degrees. However, in everyday language, if I told you that it was 23 degrees outside and it turned out to be 22.9998 degrees, you probably wouldnt call me a liar. Because in everyday language, 23 degrees usually means something like somewhere between 22.5 and 23.5 degrees. And while it doesnt feel very meaningful to ask about the probability that the temperature is exactly 23 degrees, it does seem sensible to ask about the probability that the temperature lies between 22.5 and 23.5, or between 20 and 30, or any other range of temperatures. The point of this discussion is to make clear that, when were talking about continuous distributions, its not meaningful to talk about the probability of a specific value. However, what we can talk about is the probability that the value lies within a particular range of values. To find out the probability associated with a particular range, what you need to do is calculate the area under the curve. Weve seen this concept already: in Figure 3.9, the shaded areas shown depict genuine probabilities (e.g., in the left hand panel of Figure 3.9 it shows the probability of observing a value that falls within 1 standard deviation of the mean). Okay, so that explains part of the story. Ive explained a little bit about how continuous probability distributions should be interpreted (i.e., area under the curve is the key thing), but I havent actually explained what the dnorm() function actually calculates. Equivalently, what does the formula for \\(p(x)\\) that I described earlier actually mean? Obviously, \\(p(x)\\) doesnt describe a probability, but what is it? The name for this quantity \\(p(x)\\) is a probability density, and in terms of the plots weve been drawing, it corresponds to the height of the curve. The densities themselves arent meaningful in and of themselves: but theyre rigged to ensure that the area under the curve is always interpretable as genuine probabilities. To be honest, thats about as much as you really need to know for now.7 3.6 Other useful distributions The normal distribution is the distribution that statistics makes most use of (for reasons to be discussed shortly), and the binomial distribution is a very useful one for lots of purposes. But the world of statistics is filled with probability distributions, some of which well run into in passing. In particular, the three that will appear in this book are the \\(t\\) distribution, the \\(\\chi^2\\) distribution and the \\(F\\) distribution. I wont give formulas for any of these, or talk about them in too much detail, but I will show you some pictures. The \\(t\\) distribution is a continuous distribution that looks very similar to a normal distribution, but has heavier tails: see Figure 3.11. This distribution tends to arise in situations where you think that the data actually follow a normal distribution, but you dont know the mean or standard deviation. As you might expect, the relevant R functions are dt(), pt(), qt() and rt(), and well run into this distribution again in Chapter ??. Figure 3.11: A \\(t\\) distribution with 3 degrees of freedom (solid line). It looks similar to a normal distribution, but its not quite the same. For comparison purposes, Ive plotted a standard normal distribution as the dashed line. Note that the tails of the \\(t\\) distribution are heavier (i.e., extend further outwards) than the tails of the normal distribution? Thats the important difference between the two. The \\(\\chi^2\\) distribution is another distribution that turns up in lots of different places. The situation in which well see it is when doing categorical data analysis (Chapter ??), but its one of those things that actually pops up all over the place. When you dig into the maths (and who doesnt love doing that?), it turns out that the main reason why the \\(\\chi^2\\) distribution turns up all over the place is that, if you have a bunch of variables that are normally distributed, square their values and then add them up (a procedure referred to as taking a sum of squares), this sum has a \\(\\chi^2\\) distribution. Youd be amazed how often this fact turns out to be useful. Anyway, heres what a \\(\\chi^2\\) distribution looks like: Figure 3.12. Once again, the R commands for this one are pretty predictable: dchisq(), pchisq(), qchisq(), rchisq(). Figure 3.12: A \\(chi^2\\) distribution with 3 degrees of freedom. Notice that the observed values must always be greater than zero, and that the distribution is pretty skewed. These are the key features of a chi-square distribution. The \\(F\\) distribution looks a bit like a \\(\\chi^2\\) distribution, and it arises whenever you need to compare two \\(\\chi^2\\) distributions to one another. Admittedly, this doesnt exactly sound like something that any sane person would want to do, but it turns out to be very important in real world data analysis. Remember when I said that \\(\\chi^2\\) turns out to be the key distribution when were taking a sum of squares? Well, what that means is if you want to compare two different sums of squares, youre probably talking about something that has an \\(F\\) distribution. Of course, as yet I still havent given you an example of anything that involves a sum of squares, but I will in Chapter ??. And thats where well run into the \\(F\\) distribution. Oh, and heres a picture: Figure 3.13. And of course we can get R to do things with \\(F\\) distributions just by using the commands df(), pf(), qf() and rf(). Figure 3.13: An \\(F\\) distribution with 3 and 5 degrees of freedom. Qualitatively speaking, it looks pretty similar to a chi-square distribution, but theyre not quite the same in general. Because these distributions are all tightly related to the normal distribution and to each other, and because they are will turn out to be the important distributions when doing inferential statistics later in this book, I think its useful to do a little demonstration using R, just to convince ourselves that these distributions really are related to each other in the way that theyre supposed to be. First, well use the rnorm() function to generate 1000 normally-distributed observations: normal.a &lt;- rnorm( n=1000, mean=0, sd=1 ) print(head(normal.a)) #&gt; [1] -0.216 0.426 0.229 -0.570 -0.268 -0.738 So the normal.a variable contains 1000 numbers that are normally distributed, and have mean 0 and standard deviation 1, and the actual print out of these numbers goes on for rather a long time. Note that, because the default parameters of the rnorm() function are mean=0 and sd=1, I could have shortened the command to rnorm( n=1000 ). In any case, what we can do is use the hist() function to draw a histogram of the data, like so: hist( normal.a ) If you do this, you should see something similar to Figure 3.14. Your plot wont look quite as pretty as the one in the figure, of course, because Ive played around with all the formatting (see Chapter ??), and Ive also plotted the true distribution of the data as a solid black line (i.e., a normal distribution with mean 0 and standard deviation 1) so that you can compare the data that we just generated to the true distribution. Figure 3.14: A histogram of different distributions with some advanced formatting In the previous example all I did was generate lots of normally distributed observations using rnorm() and then compared those to the true probability distribution in the figure (using dnorm() to generate the black line in the figure, but I didnt show the commmands for that). Now lets try something trickier. Well try to generate some observations that follow a chi-square distribution with 3 degrees of freedom, but instead of using rchisq(), well start with variables that are normally distributed, and see if we can exploit the known relationships between normal and chi-square distributions to do the work. As I mentioned earlier, a chi-square distribution with \\(k\\) degrees of freedom is what you get when you take \\(k\\) normally-distributed variables (with mean 0 and standard deviation 1), square them, and add them up. Since we want a chi-square distribution with 3 degrees of freedom, well need to supplement our normal.a data with two more sets of normally-distributed observations, imaginatively named normal.b and normal.c: normal.b &lt;- rnorm( n=1000 ) # another set of normally distributed data normal.c &lt;- rnorm( n=1000 ) # and another! Now that weve done that, the theory says we should square these and add them together, like this chi.sq.3 &lt;- (normal.a)^2 + (normal.b)^2 + (normal.c)^2 and the resulting chi.sq.3 variable should contain 1000 observations that follow a chi-square distribution with 3 degrees of freedom. You can use the hist() function to have a look at these observations yourself, using a command like this, hist( chi.sq.3 ) and you should obtain a result that looks pretty similar to the chi-square plot in Figure 3.14. Once again, the plot that Ive drawn is a little fancier: in addition to the histogram of chi.sq.3, Ive also plotted a chi-square distribution with 3 degrees of freedom. Its pretty clear that  even though I used rnorm() to do all the work rather than rchisq()  the observations stored in the chi.sq.3 variable really do follow a chi-square distribution. Admittedly, this probably doesnt seem all that interesting right now, but later on when we start encountering the chi-square distribution in Chapter ??, it will be useful to understand the fact that these distributions are related to one another. We can extend this demonstration to the \\(t\\) distribution and the \\(F\\) distribution. Earlier, I implied that the \\(t\\) distribution is related to the normal distribution when the standard deviation is unknown. Thats certainly true, and thats the what well see later on in Chapter ??, but theres a somewhat more precise relationship between the normal, chi-square and \\(t\\) distributions. Suppose we scale our chi-square data by dividing it by the degrees of freedom, like so scaled.chi.sq.3 &lt;- chi.sq.3 / 3 We then take a set of normally distributed variables and divide them by (the square root of) our scaled chi-square variable which had \\(df=3\\), and the result is a \\(t\\) distribution with 3 degrees of freedom. If we plot the histogram of t.3, we end up with something that looks very similar to the t distribution in Figure 3.14. normal.d &lt;- rnorm( n=1000 ) # yet another set of normally distributed data t.3 &lt;- normal.d / sqrt( scaled.chi.sq.3 ) # divide by square root of scaled chi-square to get t hist (t.3) Similarly, we can obtain an \\(F\\) distribution by taking the ratio between two scaled chi-square distributions. Suppose, for instance, we wanted to generate data from an \\(F\\) distribution with 3 and 20 degrees of freedom. We could do this using df(), but we could also do the same thing by generating two chi-square variables, one with 3 degrees of freedom, and the other with 20 degrees of freedom. As the example with chi.sq.3 illustrates, we can actually do this using rnorm() if we really want to, but this time Ill take a short cut: chi.sq.20 &lt;- rchisq( 1000, 20) # generate chi square data with df = 20... scaled.chi.sq.20 &lt;- chi.sq.20 / 20 # scale the chi square variable... F.3.20 &lt;- scaled.chi.sq.3 / scaled.chi.sq.20 # take the ratio of the two chi squares... hist( F.3.20 ) # ... and draw a picture The resulting F.3.20 variable does in fact store variables that follow an \\(F\\) distribution with 3 and 20 degrees of freedom. This is illustrated in Figure 3.14, which plots the histgram of the observations stored in F.3.20 against the true \\(F\\) distribution with \\(df_1 = 3\\) and \\(df_2 = 20\\). Again, they match. Okay, time to wrap this section up. Weve seen three new distributions: \\(\\chi^2\\), \\(t\\) and \\(F\\). Theyre all continuous distributions, and theyre all closely related to the normal distribution. Ive talked a little bit about the precise nature of this relationship, and shown you some R commands that illustrate this relationship. The key thing for our purposes, however, is not that you have a deep understanding of all these different distributions, nor that you remember the precise relationships between them. The main thing is that you grasp the basic idea that these distributions are all deeply related to one another, and to the normal distribution. Later on in this book, were going to run into data that are normally distributed, or at least assumed to be normally distributed. What I want you to understand right now is that, if you make the assumption that your data are normally distributed, you shouldnt be surprised to see \\(\\chi^2\\), \\(t\\) and \\(F\\) distributions popping up all over the place when you start trying to do your data analysis. 3.7 Summary In this chapter weve talked about probability. Weve talked what probability means, and why statisticians cant agree on what it means. We talked about the rules that probabilities have to obey. And we introduced the idea of a probability distribution, and spent a good chunk of the chapter talking about some of the more important probability distributions that statisticians work with. The section by section breakdown looks like this: Probability theory versus statistics (Section 3.1) Frequentist versus Bayesian views of probability (Section 3.2) Basics of probability theory (Section 3.3) Binomial distribution (Section 3.4), normal distribution (Section 3.5), and others (Section 3.6) As youd expect, my coverage is by no means exhaustive. Probability theory is a large branch of mathematics in its own right, entirely separate from its application to statistics and data analysis. As such, there are thousands of books written on the subject and universities generally offer multiple classes devoted entirely to probability theory. Even the simpler task of documenting standard probability distributions is a big topic. Ive described five standard probability distributions in this chapter, but sitting on my bookshelf I have a 45-chapter book called Statistical Distributions (Evans2000?) that lists a lot more than that. Fortunately for you, very little of this is necessary. Youre unlikely to need to know dozens of statistical distributions when you go out and do real world data analysis, and you definitely wont need them for this book, but it never hurts to know that theres other possibilities out there. Picking up on that last point, theres a sense in which this whole chapter is something of a digression. Many undergraduate psychology classes on statistics skim over this content very quickly (I know mine did), and even the more advanced classes will often forget to revisit the basic foundations of the field. Most academic psychologists would not know the difference between probability and density, and until recently very few would have been aware of the difference between Bayesian and frequentist probability. However, I think its important to understand these things before moving onto the applications. For example, there are a lot of rules about what youre allowed to say when doing statistical inference, and many of these can seem arbitrary and weird. However, they start to make sense if you understand that there is this Bayesian/frequentist distinction. Similarly, in Chapter ?? were going to talk about something called the \\(t\\)-test, and if you really want to have a grasp of the mechanics of the \\(t\\)-test it really helps to have a sense of what a \\(t\\)-distribution actually looks like. You get the idea, I hope. This doesnt mean that frequentists cant make hypothetical statements, of course; its just that if you want to make a statement about probability, then it must be possible to redescribe that statement in terms of a sequence of potentially observable events, and the relative frequencies of different outcomes that appear within that sequence. Note that the term success is pretty arbitrary, and doesnt actually imply that the outcome is something to be desired. If \\(\\theta\\) referred to the probability that any one passenger gets injured in a bus crash, Id still call it the success probability, but that doesnt mean I want people to get hurt in bus crashes! Since computers are deterministic machines, they cant actually produce truly random behaviour. Instead, what they do is take advantage of various mathematical functions that share a lot of similarities with true randomness. What this means is that any random numbers generated on a computer are pseudorandom, and the quality of those numbers depends on the specific method used. By default R uses the Mersenne twister method. In any case, you can find out more by typing ?Random, but as usual the R help files are fairly dense. In practice, the normal distribution is so handy that people tend to use it even when the variable isnt actually continuous. As long as there are enough categories (e.g., Likert scale responses to a questionnaire), its pretty standard practice to use the normal distribution as an approximation. This works out much better in practice than youd think. For those readers who know a little calculus, Ill give a slightly more precise explanation. In the same way that probabilities are non-negative numbers that must sum to 1, probability densities are non-negative numbers that must integrate to 1 (where the integral is taken across all possible values of \\(X\\)). To calculate the probability that \\(X\\) falls between \\(a\\) and \\(b\\) we calculate the definite integral of the density function over the corresponding range, \\(\\int_a^b p(x) \\ dx\\). If you dont remember or never learned calculus, dont worry about this. Its not needed for this book. "],["good-resources.html", "4 Good Resources", " 4 Good Resources https://psychnerdjae.github.io/into-the-tidyverse/ Automatic Grading with RMarkdown example Git/Github for virtual learning (from this tweet) Learn-Datascience-for-Free https://allisonhorst.shinyapps.io/dplyr-learnr/ Visualizing Linear Models: An R Bag of Tricks "],["media-without-a-home-yet.html", "5 Media without a home yet 5.1 Visualizing Linear Models: An R Bag of Tricks 5.2 For new programmers learning keyboard shortcuts 5.3 Are you a student? If yes, this is the best data science project for you! 5.4 rstudio is magic 5.5 automation quote 5.6 How computer memory works! 5.7 Is Coding a Math Skill or a Language Skill? Neither? Both? 5.8 Quantum Computers Explained! 5.9 The Rise of the Machines  Why Automation is Different this Time 5.10 Who Would Be King of America if George Washington had been made a monarch? 5.11 Emergence  How Stupid Things Become Smart Together 5.12 The Birthday Paradox 5.13 Why cant you divide by zero? 5.14 Yea hes chewing up my stats homework but that face though 5.15 Coding Kitty 5.16 Democratic databases: science on GitHub 5.17 Ten simple rules for getting started on Twitter as a scientist 5.18 NYT data ethics stuff 5.19 ", " 5 Media without a home yet 5.1 Visualizing Linear Models: An R Bag of Tricks I&#39;m starting a 3-week #rstats short course, Visualizing Linear Models: An R Bag of Tricks.One week on univariate models, two weeks on models for multivariate responses. Lectures notes, examples and exercises are at: https://t.co/LF1iVPZOPs&mdash; Michael Friendly (@datavisFriendly) February 27, 2021 5.2 For new programmers learning keyboard shortcuts https://www.shortcutfoo.com/ 5.3 Are you a student? If yes, this is the best data science project for you! 5.4 rstudio is magic Multiple cursors in @RStudio are so handy! Holding down the option key and drag gives me multiple synced cursors  pic.twitter.com/nQKzqIwsou&mdash; Emil Hvitfeldt (@Emil_Hvitfeldt) February 2, 2021 5.5 automation quote &quot;Ive always objected to doing anything over again if I had already done it once.&quot;  Grace Hopper&mdash; Programming Wisdom (@CodeWisdom) February 8, 2021 5.6 How computer memory works! 5.7 Is Coding a Math Skill or a Language Skill? Neither? Both? 5.8 Quantum Computers Explained! 5.9 The Rise of the Machines  Why Automation is Different this Time 5.10 Who Would Be King of America if George Washington had been made a monarch? 5.11 Emergence  How Stupid Things Become Smart Together 5.12 The Birthday Paradox 5.13 Why cant you divide by zero? 5.14 Yea hes chewing up my stats homework but that face though Yea hes chewing up my stats homework but that face though from r/CatsBeingCats 5.15 Coding Kitty https://hostrider.com/ 5.16 Democratic databases: science on GitHub Nature: Democratic databases: science on GitHub (Perkel, 2016). 5.17 Ten simple rules for getting started on Twitter as a scientist https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1007513 5.18 NYT data ethics stuff https://www.nytimes.com/2021/01/31/technology/facial-recognition-photo-tool.html 5.19 Art! https://t.co/XuDToJAmnp&mdash; Prof. S. Mason Garrison  (@SMasonGarrison) March 18, 2021 "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
